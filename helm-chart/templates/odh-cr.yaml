---
apiVersion: opendatahub.io/v1alpha1
kind: OpenDataHub
metadata:
  namespace: {{ .Values.namespace }}
  name: {{ include "odh.fullname" . }}
  labels:
    {{- include "ml-aml-workshop.labels" . | nindent 4 }}
  namespace: {{ .Values.namespace }}
spec:
  aicoe-jupyterhub:
    spark_configmap_template: jupyterhub-spark-operator-configmap
    spark_home: /opt/app-root/lib/python3.6/site-packages/pyspark/
    db_memory: 1Gi
    spark_pythonpath: >-
      $PYTHONPATH:/opt/app-root/lib/python3.6/site-packages/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/:/opt/app-root/lib/python3.6/site-packages/pyspark/python/lib/py4j-0.8.2.1-src.zip
    notebook_cpu: 2
    s3_endpoint_url: ''
    notebook_memory: 4Gi
    spark_pyspark_driver_python: jupyter
    repository: odh-jupyterhub
    odh_deploy: true
    storage_class: null
    gpu_mode: ''
    user_pvc_size: 2Gi
    notebook_image: 's2i-minimal-notebook:3.6'
    spark_pyspark_submit_args: >-
      --conf spark.cores.max=6 --conf spark.executor.instances=2 --conf
      spark.executor.memory=3G --conf spark.executor.cores=3 --conf
      spark.driver.memory=4G --packages
      com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.3
      pyspark-shell
    jupyterhub_memory: 1Gi
    spark_pyspark_driver_python_opts: notebook
    notebook_images:
      deploy_all_notebooks: true
      deploy_cuda_notebooks: false
    registry: quay.io
    spark:
      image: 'quay.io/opendatahub/spark-cluster-image:spark22python36'
      master:
        instances: 1
        resources:
          limits:
            cpu: 1
            memory: 1Gi
          requests:
            cpu: 250m
            memory: 512Mi
      worker:
        instances: 1
        resources:
          limits:
            cpu: 3
            memory: 4Gi
          requests:
            cpu: 250m
            memory: 1Gi
  kafka:
    kafka_broker_replicas: 3
    kafka_cluster_name: odh-message-bus
    kafka_zookeeper_replicas: 3
    odh_deploy: false
  superset:
    data_volume_size: 512Mi
    image: 'quay.io/aiops/superset:v0.30'
    odh_deploy: false
    secret_key: thisISaSECRET_1234
    sqlalchemy_db_uri: 'sqlite:////var/lib/superset/superset.db'
    superset_admin:
      admin_email: admin@fab.org
      admin_fname: admin
      admin_lname: admin
      admin_psw: 7ujmko0
      admin_usr: userKPJ
  monitoring:
    enable_pushgateway: false
    odh_deploy: true
  seldon:
    odh_deploy: true
  spark-operator:
    master:
      instances: 1
      resources:
        limits:
          cpu: 1
          memory: 1Gi
        requests:
          cpu: 250m
          memory: 512Mi
    odh_deploy: true
    worker:
      instances: 1
      resources:
        limits:
          cpu: 1
          memory: 2Gi
        requests:
          cpu: 250m
          memory: 512Mi
  ai-library:
    odh_deploy: false
  data-catalog:
    s3_port: 8080
    spark-cluster:
      master_cpu: 250m
      master_memory: 1Gi
      master_node_count: 1
      spark_cluster_name: spark-cluster-data-catalog
      spark_image: 'quay.io/opendatahub/spark-cluster-image:spark24'
      worker_cpu: 250m
      worker_memory: 2Gi
      worker_node_count: 2
    s3_is_secure: false
    aws_secret_access_key: changeme
    odh_deploy: false
    aws_access_key_id: changeme
    s3_endpoint: s3.foo.com
    thrift-server:
      spark_cluster_port: 7077
      spark_max_cores: 6
    hue:
      database:
        image: registry.access.redhat.com/rhscl/mysql-57-rhel7
        memory_limit: 1Gi
        password: changeme
        root_password: changeme
        username: changeme
        volume_capacity: 10Gi
      hue_secret_key: changeme
    hive-metastore:
      database:
        driver: org.postgresql.Driver
        image: registry.access.redhat.com/rhscl/postgresql-96-rhel7
        memory_limit: 1Gi
        password: changeme
        username: changeme
        volume_capacity: 10Gi
      warehouse_volume_capacity: 10Gi
  argo:
    odh_deploy: true
  beakerx:
    odh_deploy: false
